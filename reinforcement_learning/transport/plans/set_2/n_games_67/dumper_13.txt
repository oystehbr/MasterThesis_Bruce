###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    912.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  0.16978    0.16978    0.16978    0.16978    0.16978   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7fad1cf01160>   
waiting_time:  182.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  14.85024   
coffee_state: [ 4.68571429 10.         14.44642857 14.27870655]   
coffee_pred: tensor([10.8846, 13.4370], grad_fn=<AddBackward0>)   

###1### start: 00:15:12
full_route: full_reward: state_info: start_end_time:  912.00000    1380.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  7.60421    7.60421    7.60421    7.60421   
state_plan: <helper.State object at 0x7faccf7240d0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:23:00
full_route: full_reward: state_info: start_end_time:  1380.00000    2008.00000   
actual_route: D57   N67   N77   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  6.13834    6.13834    6.13834    6.13834   
state_plan: <helper.State object at 0x7faccf8c54c0>   
plan: L97   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  129.00000   
mass_end:  40.00000   
driving_time:  436.60000   
plan_reward:  20.92447   
coffee_state: [ 3.89821429  7.6875     10.54642857 31.36769867]   
coffee_pred: tensor([20.6799, 29.2225], grad_fn=<AddBackward0>)   

###3### start: 00:33:28
full_route: full_reward: state_info: start_end_time:  2008.00000    2476.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  1.69492    1.69492    1.69492    1.69492   
state_plan: <helper.State object at 0x7facc14449a0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  32.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  26.19815   

###4### start: 00:41:16
full_route: full_reward: state_info: start_end_time:  2476.00000    3547.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.13649    0.13649    0.13649    0.13649   
state_plan: <helper.State object at 0x7faccf732df0>   
plan: L17   
mass_type: 0   
waiting_time:  412.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  15.67621   
coffee_state: [ 4.17142857 10.         11.05714286 16.63764381]   
coffee_pred: tensor([12.4992, 16.0377], grad_fn=<AddBackward0>)   

###5### start: 00:59:07
full_route: full_reward: state_info: start_end_time:  3547.00000    4046.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  7.10616    7.10616    7.10616    7.10616   
state_plan: <helper.State object at 0x7facc14887f0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  16.95777   

###6### start: 01:07:26
full_route: full_reward: state_info: start_end_time:  4046.00000    4771.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  14.38768    14.38768    14.38768    14.38768    14.38768    14.38768   
state_plan: <helper.State object at 0x7faccf98d760>   
plan: L8   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  378.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  20.79471   
coffee_state: [ 4.75357143 10.          9.85357143  9.42343712]   
coffee_pred: tensor([ 9.8050, 11.9320], grad_fn=<AddBackward0>)   

###7### start: 01:19:31
full_route: full_reward: state_info: start_end_time:  4771.00000    5839.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103    10.51103   
state_plan: <helper.State object at 0x7faccf9bd940>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  538.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

