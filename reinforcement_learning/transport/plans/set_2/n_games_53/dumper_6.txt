###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    665.00000   
actual_route: P83   N82   L72   
mass:  0.00000    40.00000   
actual_reward:  0.25674    0.25674   
plan: L72   
mass_type: 0   
state_plan: <helper.State object at 0x7faccf098bb0>   
waiting_time:  185.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  282.40000   
plan_reward:  26.61403   
coffee_state: [ 2.52142857 10.          9.13214286 15.69759846]   
coffee_pred: tensor([13.4130, 17.7558], grad_fn=<AddBackward0>)   

###1### start: 00:11:05
full_route: full_reward: state_info: start_end_time:  665.00000    1016.00000   
actual_route: L72   N62   N61   D60   
mass:  40.00000    0.00000   
actual_reward:  61.97624    61.97624    61.97624   
state_plan: <helper.State object at 0x7facc0b384f0>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  986.00000   
mass_end:  0.00000   
driving_time:  319.80000   
plan_reward:  40.68168   

###2### start: 00:16:56
full_route: full_reward: state_info: start_end_time:  1016.00000    1671.00000   
actual_route: D60   N50   N40   N30   N31   L32   
mass:  0.00000    40.00000   
actual_reward:  12.59707    12.59707    12.59707    12.59707    12.59707   
state_plan: <helper.State object at 0x7facfac43c40>   
plan: L32   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  287.00000   
mass_end:  40.00000   
driving_time:  463.60000   
plan_reward:  22.81816   
coffee_state: [ 4.13928571 10.          5.86785714 26.95386124]   
coffee_pred: tensor([16.2670, 22.2022], grad_fn=<AddBackward0>)   

###3### start: 00:27:51
full_route: full_reward: state_info: start_end_time:  1671.00000    2038.00000   
actual_route: L32   N33   N43   N53   D63   
mass:  40.00000    0.00000   
actual_reward:  6.07143    6.07143    6.07143    6.07143   
state_plan: <helper.State object at 0x7facc0f2f670>   
plan: D63   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  97.00000   
mass_end:  0.00000   
driving_time:  336.00000   
plan_reward:  32.85354   

###4### start: 00:33:58
full_route: full_reward: state_info: start_end_time:  2038.00000    2817.00000   
actual_route: D63   N53   N43   N33   L32   
mass:  0.00000    40.00000   
actual_reward:  0.20408    0.20408    0.20408    0.20408   
state_plan: <helper.State object at 0x7fad1cbd0bb0>   
plan: L32   
mass_type: 0   
waiting_time:  252.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  336.00000   
plan_reward:  22.12585   
coffee_state: [ 3.         10.          6.40178571 23.88152695]   
coffee_pred: tensor([16.2850, 22.3852], grad_fn=<AddBackward0>)   

###5### start: 00:46:57
full_route: full_reward: state_info: start_end_time:  2817.00000    3471.00000   
actual_route: L32   N33   N34   N35   N36   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  1.19239    1.19239    1.19239    1.19239    1.19239    1.19239    1.19239   
state_plan: <helper.State object at 0x7facfac03c10>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  32.00000   
mass_end:  0.00000   
driving_time:  620.60000   
plan_reward:  14.13209   

###6### start: 00:57:51
full_route: full_reward: state_info: start_end_time:  3471.00000    4196.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  14.19985    14.19985    14.19985    14.19985    14.19985    14.19985   
state_plan: <helper.State object at 0x7fad1cba3100>   
plan: L8   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  373.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  20.69547   
coffee_state: [ 4.75357143 10.         10.72857143 17.75289917]   
coffee_pred: tensor([14.4967, 18.3002], grad_fn=<AddBackward0>)   

###7### start: 01:09:56
full_route: full_reward: state_info: start_end_time:  4196.00000    5070.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   N43   N53   D63   
mass:  40.00000   
actual_reward:  3.02381    3.02381    3.02381    3.02381    3.02381    3.02381    3.02381    3.02381    3.02381    3.02381    3.02381   
state_plan: <helper.State object at 0x7facfad23b80>   
plan: D63   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  122.00000   
mass_end:  0.00000   
driving_time:  840.00000   
plan_reward:  13.55208   

