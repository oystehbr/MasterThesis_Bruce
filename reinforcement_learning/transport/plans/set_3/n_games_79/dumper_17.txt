###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    1293.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  0.11072    0.11072    0.11072    0.11072    0.11072   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7fad1cdcd2e0>   
waiting_time:  559.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  13.67344   
coffee_state: [ 4.68571429 10.         15.33214286 12.17821598]   
coffee_pred: tensor([13.0530, 16.9899], grad_fn=<AddBackward0>)   

###1### start: 00:21:33
full_route: full_reward: state_info: start_end_time:  1293.00000    1782.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  0.26224    0.26224    0.26224    0.26224   
state_plan: <helper.State object at 0x7facc19d7670>   
plan: D57   
mass_type: 0   
waiting_time:  21.00000   
time_since_last_used_node:  1.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:29:42
full_route: full_reward: state_info: start_end_time:  1782.00000    2441.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  17.50856    17.50856    17.50856    17.50856   
state_plan: <helper.State object at 0x7facc1692820>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  404.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  25.72570   
coffee_state: [ 4.17142857  8.69642857  9.19107143 23.9475975 ]   
coffee_pred: tensor([17.5701, 26.8002], grad_fn=<AddBackward0>)   

###3### start: 00:40:41
full_route: full_reward: state_info: start_end_time:  2441.00000    2940.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  4.70890    4.70890    4.70890    4.70890   
state_plan: <helper.State object at 0x7facc1753190>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  105.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  24.67754   

###4### start: 00:49:48
full_route: full_reward: state_info: start_end_time:  2988.00000    3726.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.21970    0.21970    0.21970    0.21970   
state_plan: <helper.State object at 0x7faca81acdf0>   
plan: L17   
mass_type: 0   
coffee_break:  48.00000   
waiting_time:  79.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  17.04397   
coffee_state: [ 4.17142857 10.          8.95357143 17.82837677]   
coffee_pred: tensor([14.6453, 19.8672], grad_fn=<AddBackward0>)   

###5### start: 01:02:06
full_route: full_reward: state_info: start_end_time:  3726.00000    4225.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  7.10616    7.10616    7.10616    7.10616   
state_plan: <helper.State object at 0x7faca809b3a0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  15.72776   

###6### start: 01:10:25
full_route: full_reward: state_info: start_end_time:  4225.00000    5178.00000   
actual_route: D57   N47   N37   N27   L17   N16   L15   
mass:  0.00000    40.00000   
actual_reward:  0.15785    0.15785    0.15785    0.15785    0.15785    0.15785   
state_plan: <helper.State object at 0x7facc1ad22e0>   
plan: L15   
mass_type: 0   
waiting_time:  112.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  648.20000   
plan_reward:  12.27915   
coffee_state: [ 5.7875      6.01428571 11.90714286 12.48874283]   
coffee_pred: tensor([12.4795, 14.0680], grad_fn=<AddBackward0>)   

###7### start: 01:26:18
full_route: full_reward: state_info: start_end_time:  5178.00000    5998.00000   
actual_route: L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855   
state_plan: <helper.State object at 0x7facc1b076a0>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  787.00000   
plan_reward:  16.53113   

