###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    914.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  0.16906    0.16906    0.16906    0.16906    0.16906   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7fad1d192b50>   
waiting_time:  185.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  14.84008   
coffee_state: [ 4.68571429 10.         14.44642857 14.0045681 ]   
coffee_pred: tensor([11.3723, 16.1148], grad_fn=<AddBackward0>)   

###1### start: 00:15:14
full_route: full_reward: state_info: start_end_time:  914.00000    1382.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  7.60421    7.60421    7.60421    7.60421   
state_plan: <helper.State object at 0x7facfb224670>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:23:02
full_route: full_reward: state_info: start_end_time:  1382.00000    2041.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  5.26541    5.26541    5.26541    5.26541   
state_plan: <helper.State object at 0x7facc1cca220>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  118.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  19.20806   
coffee_state: [ 4.17142857  8.78571429  9.275      14.4479475 ]   
coffee_pred: tensor([11.3246, 15.8090], grad_fn=<AddBackward0>)   

###3### start: 00:34:01
full_route: full_reward: state_info: start_end_time:  2041.00000    2540.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  7.61986    7.61986    7.61986    7.61986   
state_plan: <helper.State object at 0x7facc19b3370>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  173.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  20.10198   

###4### start: 00:42:20
full_route: full_reward: state_info: start_end_time:  2540.00000    3199.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.77055    0.77055    0.77055    0.77055   
state_plan: <helper.State object at 0x7facc1c978b0>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  13.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  17.57348   
coffee_state: [ 4.17142857  4.28214286 10.25357143 13.4126358 ]   
coffee_pred: tensor([11.7093, 16.6618], grad_fn=<AddBackward0>)   

###5### start: 00:53:19
full_route: full_reward: state_info: start_end_time:  3199.00000    3698.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  6.46404    6.46404    6.46404    6.46404   
state_plan: <helper.State object at 0x7faca80435e0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  146.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  15.72776   

###6### start: 01:01:38
full_route: full_reward: state_info: start_end_time:  3698.00000    4438.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  0.21922    0.21922    0.21922    0.21922    0.21922    0.21922   
state_plan: <helper.State object at 0x7fad1d19fc40>   
plan: L8   
mass_type: 0   
waiting_time:  15.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.21922   
coffee_state: [ 4.75357143 10.         10.74821429 14.55901527]   
coffee_pred: tensor([11.7939, 15.7795], grad_fn=<AddBackward0>)   

###7### start: 01:13:58
full_route: full_reward: state_info: start_end_time:  4438.00000    5506.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332   
state_plan: <helper.State object at 0x7faca859ca00>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

