###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    721.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  20.42683    20.42683    20.42683    20.42683    20.42683   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7facc1ac55b0>   
waiting_time:  0.00000   
time_since_last_used_node:  531.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  24.93866   
coffee_state: [ 4.68571429 10.         15.33214286 24.19840813]   
coffee_pred: tensor([14.7542, 22.9236], grad_fn=<AddBackward0>)   

###1### start: 00:12:01
full_route: full_reward: state_info: start_end_time:  721.00000    1189.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  53.32112    53.32112    53.32112    53.32112   
state_plan: <helper.State object at 0x7faca835b700>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1159.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:19:49
full_route: full_reward: state_info: start_end_time:  1189.00000    1848.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  71.19007    71.19007    71.19007    71.19007   
state_plan: <helper.State object at 0x7faca86d70a0>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1658.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  80.00000   
coffee_state: [ 4.17142857  8.80357143  9.275      56.38708496]   
coffee_pred: tensor([26.4746, 46.7789], grad_fn=<AddBackward0>)   

###3### start: 00:30:48
full_route: full_reward: state_info: start_end_time:  1848.00000    2366.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  0.24681    0.24681    0.24681    0.24681   
state_plan: <helper.State object at 0x7faca82eb370>   
plan: D57   
mass_type: 0   
waiting_time:  19.00000   
time_since_last_used_node:  1.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  22.15599   

###4### start: 00:39:26
full_route: full_reward: state_info: start_end_time:  2366.00000    3185.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.19133    0.19133    0.19133    0.19133   
state_plan: <helper.State object at 0x7facc1ea7550>   
plan: L17   
mass_type: 0   
waiting_time:  160.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  16.68976   
coffee_state: [ 4.17142857  4.13035714  8.99821429 21.36964607]   
coffee_pred: tensor([13.9539, 23.6288], grad_fn=<AddBackward0>)   

###5### start: 00:53:05
full_route: full_reward: state_info: start_end_time:  3185.00000    3684.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  7.10616    7.10616    7.10616    7.10616   
state_plan: <helper.State object at 0x7facfb2dda30>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  13.73522   

###6### start: 01:01:24
full_route: full_reward: state_info: start_end_time:  3684.00000    4525.00000   
actual_route: D57   N47   N37   N27   L17   N16   L15   
mass:  0.00000    40.00000   
actual_reward:  10.15119    10.15119    10.15119    10.15119    10.15119    10.15119   
state_plan: <helper.State object at 0x7facfb2f6550>   
plan: L15   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  324.00000   
mass_end:  40.00000   
driving_time:  648.20000   
plan_reward:  15.42712   
coffee_state: [ 5.7875     10.         13.14821429 15.63335228]   
coffee_pred: tensor([11.5008, 16.9357], grad_fn=<AddBackward0>)   

###7### start: 01:15:25
full_route: full_reward: state_info: start_end_time:  4525.00000    5345.00000   
actual_route: L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  0.91487    0.91487    0.91487    0.91487    0.91487    0.91487    0.91487    0.91487    0.91487    0.91487   
state_plan: <helper.State object at 0x7facc1f51c70>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  31.00000   
mass_end:  0.00000   
driving_time:  787.00000   
plan_reward:  16.53113   

