###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    665.00000   
actual_route: P83   N82   L72   
mass:  0.00000    40.00000   
actual_reward:  0.25674    0.25674   
plan: L72   
mass_type: 0   
state_plan: <helper.State object at 0x7faccd64a7f0>   
waiting_time:  185.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  282.40000   
plan_reward:  26.61403   
coffee_state: [ 2.52142857 10.          9.13214286 27.15918159]   
coffee_pred: None   

###1### start: 00:11:05
full_route: full_reward: state_info: start_end_time:  665.00000    956.00000   
actual_route: L72   N62   D63   
mass:  40.00000    0.00000   
actual_reward:  71.56034    71.56034   
state_plan: <helper.State object at 0x7fad1c343b80>   
plan: D63   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  926.00000   
mass_end:  0.00000   
driving_time:  260.20000   
plan_reward:  50.00000   

###2### start: 00:16:46
full_route: full_reward: state_info: start_end_time:  1006.00000    1974.00000   
actual_route: D63   N53   N43   N33   N23   N13   N14   L15   N16   L17   
mass:  0.00000    40.00000   
actual_reward:  3.69128    3.69128    3.69128    3.69128    3.69128    3.69128    3.69128    3.69128    3.69128   
state_plan: <helper.State object at 0x7fad1c6bfb20>   
plan: L17   
mass_type: 0   
coffee_break:  50.00000   
waiting_time:  0.00000   
time_since_last_used_node:  138.00000   
mass_end:  40.00000   
driving_time:  774.80000   
plan_reward:  11.23994   
coffee_state: [ 6.91785714 10.          9.17678571 14.59016132]   
coffee_pred: tensor([16.6037, 18.0517], grad_fn=<AddBackward0>)   

###3### start: 00:32:54
full_route: full_reward: state_info: start_end_time:  1974.00000    2976.00000   
actual_route: L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000    0.00000   
actual_reward:  0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331    0.10331   
state_plan: <helper.State object at 0x7fad1c3ff6a0>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  0.00000   
mass_end:  0.00000   
driving_time:  968.00000   
plan_reward:  12.65564   

###4### start: 00:49:47
full_route: full_reward: state_info: start_end_time:  2987.00000    3967.00000   
actual_route: D60   N50   N40   N30   N31   L32   N33   N23   N13   N14   L15   
mass:  0.00000    40.00000   
actual_reward:  15.12071    15.12071    15.12071    15.12071    15.12071    15.12071    15.12071    15.12071    15.12071    15.12071   
state_plan: <helper.State object at 0x7fad1c6a65b0>   
plan: L15   
mass_type: 0   
coffee_break:  11.00000   
waiting_time:  0.00000   
time_since_last_used_node:  590.00000   
mass_end:  40.00000   
driving_time:  787.00000   
plan_reward:  14.36299   
coffee_state: [ 7.02678571 10.          9.16785714 16.36458015]   
coffee_pred: None   

###5### start: 01:06:07
full_route: full_reward: state_info: start_end_time:  3967.00000    4648.00000   
actual_route: L15   N16   L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  23.29528    23.29528    23.29528    23.29528    23.29528    23.29528   
state_plan: <helper.State object at 0x7faccd71e0a0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  750.00000   
mass_end:  0.00000   
driving_time:  648.20000   
plan_reward:  20.07097   

###6### start: 01:17:28
full_route: full_reward: state_info: start_end_time:  4648.00000    5388.00000   
actual_route: D57   N67   N66   N65   N75   N85   N84   P83   
mass:  0.00000   
actual_reward:  0.13565    0.13565    0.13565    0.13565    0.13565    0.13565    0.13565   
state_plan: <helper.State object at 0x7faccd746b20>   
plan: P83   
mass_type: p   a   r   k   i   n   g   
waiting_time:  523.90000   
time_since_last_used_node:  0.00000   
mass_end:  0.00000   
driving_time:  737.20000   
plan_reward:  10.12530   

