###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    725.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  20.57927    20.57927    20.57927    20.57927    20.57927   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7fad1c336f40>   
waiting_time:  0.00000   
time_since_last_used_node:  535.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  25.05392   
coffee_state: [ 4.68571429 10.         15.33214286 17.36920547]   
coffee_pred: tensor([17.3311, 21.6639], grad_fn=<AddBackward0>)   

###1### start: 00:12:05
full_route: full_reward: state_info: start_end_time:  725.00000    1193.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  53.50435    53.50435    53.50435    53.50435   
state_plan: <helper.State object at 0x7facefab4e50>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1163.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:19:53
full_route: full_reward: state_info: start_end_time:  1193.00000    1924.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.22255    0.22255    0.22255    0.22255   
state_plan: <helper.State object at 0x7facefc44940>   
plan: L17   
mass_type: 0   
waiting_time:  72.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  17.07528   
coffee_state: [ 4.17142857  8.76785714  9.275      19.66583443]   
coffee_pred: tensor([17.8266, 22.6167], grad_fn=<AddBackward0>)   

###3### start: 00:32:04
full_route: full_reward: state_info: start_end_time:  1924.00000    2423.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  2.52568    2.52568    2.52568    2.52568   
state_plan: <helper.State object at 0x7facefbf5dc0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  54.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  22.15599   

###4### start: 00:40:23
full_route: full_reward: state_info: start_end_time:  2423.00000    3380.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.15682    0.15682    0.15682    0.15682   
state_plan: <helper.State object at 0x7facef7af310>   
plan: L17   
mass_type: 0   
waiting_time:  298.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  16.11904   
coffee_state: [ 4.17142857 10.          8.525      15.96292496]   
coffee_pred: tensor([14.3045, 16.8019], grad_fn=<AddBackward0>)   

###5### start: 00:56:20
full_route: full_reward: state_info: start_end_time:  3380.00000    3879.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  7.10616    7.10616    7.10616    7.10616   
state_plan: <helper.State object at 0x7faccd703130>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  16.95777   

###6### start: 01:04:39
full_route: full_reward: state_info: start_end_time:  3879.00000    4623.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  0.21763    0.21763    0.21763    0.21763    0.21763    0.21763   
state_plan: <helper.State object at 0x7faccd927c10>   
plan: L8   
mass_type: 0   
waiting_time:  19.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.20499   
coffee_state: [ 4.75357143 10.         11.05       14.24710083]   
coffee_pred: tensor([12.4241, 13.8354], grad_fn=<AddBackward0>)   

###7### start: 01:17:03
full_route: full_reward: state_info: start_end_time:  4623.00000    5691.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332   
state_plan: <helper.State object at 0x7faccd95a610>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

