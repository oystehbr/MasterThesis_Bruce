###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    474.00000   
actual_route: P83   N82   L72   
mass:  0.00000    40.00000   
actual_reward:  20.46742    20.46742   
plan: L72   
mass_type: 0   
state_plan: <helper.State object at 0x7facfa873040>   
waiting_time:  0.00000   
time_since_last_used_node:  284.00000   
mass_end:  40.00000   
driving_time:  282.40000   
plan_reward:  46.12821   

###1### start: 00:07:54
full_route: full_reward: state_info: start_end_time:  474.00000    765.00000   
actual_route: L72   N62   D63   
mass:  40.00000    0.00000   
actual_reward:  56.87932    56.87932   
state_plan: <helper.State object at 0x7facce444be0>   
plan: D63   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  735.00000   
mass_end:  0.00000   
driving_time:  260.20000   
plan_reward:  50.00000   

###2### start: 00:12:45
full_route: full_reward: state_info: start_end_time:  765.00000    1799.00000   
actual_route: D63   N53   N43   N33   N23   N13   N14   L15   N16   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  38.42857    38.42857    38.42857    38.42857    38.42857    38.42857    38.42857    38.42857    38.42857    38.42857    38.42857   
state_plan: <helper.State object at 0x7faccea79a00>   
plan: L8   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1609.00000   
mass_end:  40.00000   
driving_time:  840.00000   
plan_reward:  34.30907   
coffee_state: [ 7.5        10.         10.22321429 34.60586166]   
coffee_pred: tensor([23.7554, 27.7584], grad_fn=<AddBackward0>)   

###3### start: 00:29:59
full_route: full_reward: state_info: start_end_time:  1799.00000    2365.00000   
actual_route: L8   N7   L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  0.22497    0.22497    0.22497    0.22497    0.22497    0.22497   
state_plan: <helper.State object at 0x7facc0676e20>   
plan: D57   
mass_type: 0   
waiting_time:  1.00000   
time_since_last_used_node:  1.00000   
mass_end:  0.00000   
driving_time:  532.40000   
plan_reward:  21.96151   

###4### start: 00:39:25
full_route: full_reward: state_info: start_end_time:  2365.00000    3090.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  1.38993    1.38993    1.38993    1.38993    1.38993    1.38993   
state_plan: <helper.State object at 0x7fad1c54d070>   
plan: L8   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  32.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.61375   
coffee_state: [ 4.75357143 10.          9.58035714 17.95772934]   
coffee_pred: tensor([15.8128, 18.6988], grad_fn=<AddBackward0>)   

###5### start: 00:51:30
full_route: full_reward: state_info: start_end_time:  3090.00000    3655.00000   
actual_route: L8   N7   L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  5.18407    5.18407    5.18407    5.18407    5.18407    5.18407   
state_plan: <helper.State object at 0x7facc0636ac0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  133.00000   
mass_end:  0.00000   
driving_time:  532.40000   
plan_reward:  13.66023   

###6### start: 01:00:55
full_route: full_reward: state_info: start_end_time:  3655.00000    4408.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  0.21413    0.21413    0.21413    0.21413    0.21413    0.21413   
state_plan: <helper.State object at 0x7facce718610>   
plan: L8   
mass_type: 0   
waiting_time:  28.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.17307   
coffee_state: [ 4.75357143 10.         10.10357143 16.59593773]   
coffee_pred: tensor([15.0761, 17.7254], grad_fn=<AddBackward0>)   

###7### start: 01:13:28
full_route: full_reward: state_info: start_end_time:  4408.00000    5476.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332   
state_plan: <helper.State object at 0x7facceb17820>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

