###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    720.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  20.38872    20.38872    20.38872    20.38872    20.38872   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7facfa91e820>   
waiting_time:  0.00000   
time_since_last_used_node:  530.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  24.91001   
coffee_state: [ 4.68571429 10.         15.33214286 20.46486473]   
coffee_pred: tensor([17.4676, 20.9074], grad_fn=<AddBackward0>)   

###1### start: 00:12:00
full_route: full_reward: state_info: start_end_time:  720.00000    1188.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  53.27531    53.27531    53.27531    53.27531   
state_plan: <helper.State object at 0x7fad1c5722b0>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1158.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  29.79844   

###2### start: 00:19:48
full_route: full_reward: state_info: start_end_time:  1188.00000    1924.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  0.22051    0.22051    0.22051    0.22051   
state_plan: <helper.State object at 0x7faccee2e4f0>   
plan: L17   
mass_type: 0   
waiting_time:  77.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  17.05290   
coffee_state: [ 4.17142857  8.8125      9.275      13.85680008]   
coffee_pred: tensor([12.8439, 15.0153], grad_fn=<AddBackward0>)   

###3### start: 00:32:04
full_route: full_reward: state_info: start_end_time:  1924.00000    2423.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  2.73973    2.73973    2.73973    2.73973   
state_plan: <helper.State object at 0x7faccea60970>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  59.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  20.10198   

###4### start: 00:40:23
full_route: full_reward: state_info: start_end_time:  2423.00000    3082.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  4.06678    4.06678    4.06678    4.06678   
state_plan: <helper.State object at 0x7faccecb8d60>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  90.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  18.74316   
coffee_state: [ 4.17142857 10.          8.48035714 15.54588509]   
coffee_pred: tensor([14.1484, 16.6078], grad_fn=<AddBackward0>)   

###5### start: 00:51:22
full_route: full_reward: state_info: start_end_time:  3082.00000    3581.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  1.45548    1.45548    1.45548    1.45548   
state_plan: <helper.State object at 0x7facce770c70>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  29.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  15.72776   

###6### start: 00:59:41
full_route: full_reward: state_info: start_end_time:  3581.00000    4306.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  2.40421    2.40421    2.40421    2.40421    2.40421    2.40421   
state_plan: <helper.State object at 0x7faccec82040>   
plan: L8   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  59.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.92333   
coffee_state: [ 4.75357143 10.         10.61428571 19.01802444]   
coffee_pred: tensor([15.7391, 18.7275], grad_fn=<AddBackward0>)   

###7### start: 01:11:46
full_route: full_reward: state_info: start_end_time:  4306.00000    5374.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614    0.11614   
state_plan: <helper.State object at 0x7facceeb6f70>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

