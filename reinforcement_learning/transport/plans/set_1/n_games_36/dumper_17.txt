###0### start: 00:00:00
full_route: full_reward: state_info: start_end_time:  0.00000    1675.00000   
actual_route: P83   N84   N85   N86   N87   L97   
mass:  0.00000    40.00000   
actual_reward:  0.08187    0.08187    0.08187    0.08187    0.08187   
plan: L97   
mass_type: 0   
state_plan: <helper.State object at 0x7facfa911670>   
waiting_time:  941.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  524.80000   
plan_reward:  12.65712   
coffee_state: [ 4.68571429 10.         14.44642857 10.86346912]   
coffee_pred: tensor([11.2269, 12.8531], grad_fn=<AddBackward0>)   

###1### start: 00:27:55
full_route: full_reward: state_info: start_end_time:  1675.00000    2143.00000   
actual_route: L97   N87   N77   N67   D57   
mass:  40.00000    0.00000   
actual_reward:  7.60421    7.60421    7.60421    7.60421   
state_plan: <helper.State object at 0x7faccec8f100>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  436.60000   
plan_reward:  26.19815   

###2### start: 00:35:43
full_route: full_reward: state_info: start_end_time:  2143.00000    2802.00000   
actual_route: D57   N47   N37   N27   L17   
mass:  0.00000    40.00000   
actual_reward:  7.10616    7.10616    7.10616    7.10616   
state_plan: <helper.State object at 0x7facceddf4f0>   
plan: L17   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  40.00000   
driving_time:  467.20000   
plan_reward:  19.96869   
coffee_state: [ 4.17142857  8.8125      9.275      19.05331612]   
coffee_pred: tensor([16.0641, 19.3455], grad_fn=<AddBackward0>)   

###3### start: 00:46:42
full_route: full_reward: state_info: start_end_time:  2802.00000    3301.00000   
actual_route: L17   N27   N37   N47   D57   
mass:  40.00000    0.00000   
actual_reward:  1.45548    1.45548    1.45548    1.45548   
state_plan: <helper.State object at 0x7facc07a6670>   
plan: D57   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  29.00000   
mass_end:  0.00000   
driving_time:  467.20000   
plan_reward:  15.72776   

###4### start: 00:55:01
full_route: full_reward: state_info: start_end_time:  3301.00000    4057.00000   
actual_route: D57   N47   N37   N27   L17   N7   L8   
mass:  0.00000    40.00000   
actual_reward:  0.21299    0.21299    0.21299    0.21299    0.21299    0.21299   
state_plan: <helper.State object at 0x7facce550280>   
plan: L8   
mass_type: 0   
waiting_time:  31.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  532.40000   
plan_reward:  15.16246   
coffee_state: [ 4.75357143 10.         10.11428571 16.22641373]   
coffee_pred: tensor([14.0611, 16.4749], grad_fn=<AddBackward0>)   

###5### start: 01:07:37
full_route: full_reward: state_info: start_end_time:  4057.00000    5125.00000   
actual_route: L8   N7   L17   N16   L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000    0.00000   
actual_reward:  3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332    3.21332   
state_plan: <helper.State object at 0x7facceeabb80>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  1033.20000   
plan_reward:  12.59195   

###6### start: 01:25:25
full_route: full_reward: state_info: start_end_time:  5125.00000    6105.00000   
actual_route: D60   N50   N40   N30   N31   L32   N33   N23   N13   N14   L15   
mass:  0.00000    40.00000   
actual_reward:  0.15248    0.15248    0.15248    0.15248    0.15248    0.15248    0.15248    0.15248    0.15248    0.15248   
state_plan: <helper.State object at 0x7facceee86d0>   
plan: L15   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  1.00000   
mass_end:  40.00000   
driving_time:  787.00000   
plan_reward:  10.33196   
coffee_state: [ 7.02678571 10.         13.02321429 13.25781536]   
coffee_pred: tensor([12.0933, 13.6202], grad_fn=<AddBackward0>)   

###7### start: 01:41:45
full_route: full_reward: state_info: start_end_time:  6105.00000    6925.00000   
actual_route: L15   N14   N13   N23   N33   L32   N31   N30   N40   N50   D60   
mass:  40.00000   
actual_reward:  4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855    4.21855   
state_plan: <helper.State object at 0x7facceef4d00>   
plan: D60   
mass_type: 0   
waiting_time:  0.00000   
time_since_last_used_node:  161.00000   
mass_end:  0.00000   
driving_time:  787.00000   
plan_reward:  16.53113   

